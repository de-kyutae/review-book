{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 뉴턴 방법으로 푸는 최적화(자동 계산)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 33.1 2차 미분 계산하기\n",
    "$y=x^{4}-2x^{2}$ 수식의 2차 미분 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variable(24.0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'First backpropagation'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from dezero import Variable\n",
    "\n",
    "def f(x):\n",
    "    \"\"\" Calculate function (x**4 - 2*x**2)\"\"\"    \n",
    "    y = x ** 4 - 2 * x ** 2\n",
    "    return y\n",
    "\n",
    "\n",
    "x = Variable(np.array(2.0))\n",
    "y = f(x)\n",
    "y.backward(create_graph=True) \n",
    "\"\"\" backprobagation of y\n",
    "\n",
    "Args : \n",
    "create_graph = True : make graph of backpropagation process\n",
    "\n",
    "\"\"\"\n",
    "print(x.grad)\n",
    "\"\"\"First differentiation\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Variable(np.array(2.0))\n",
    "y = f(x)\n",
    "y.backward(create_graph=True) \n",
    "print(x.grad)\n",
    "\"\"\"First differentiation\"\"\"\n",
    "\n",
    "gx = x.grad\n",
    "x.cleargrad() # initialize derivatioin value\n",
    "gx.backward()\n",
    "print(x.grad)\n",
    "\"\"\"Second differentiation\n",
    "\n",
    "initialize the previous derivation value\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1차 미분의 결과(24)와 2차 미분의 결과(44)가 더해져서 출력됨(68)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variable(68.0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Second backpropagation\\n\\nproblem of this function:\\nseconde return value of backpropagation is cumulated by first return value of backpropagation\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gx = x.grad\n",
    "gx.backward()\n",
    "print(x.grad)\n",
    "\"\"\"Second backpropagation\n",
    "\n",
    "problem of this function:\n",
    "seconde return value of backpropagation is cumulated by first return value of backpropagation\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variable(44.0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'defalut derivation value'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gx = x.grad\n",
    "x.cleargrad() # initialize derivatioin value\n",
    "gx.backward()\n",
    "print(x.grad)\n",
    "\"\"\"Second differentiation\n",
    "\n",
    "initialize the previous derivation value\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 33.2 뉴턴 방법을 활용한 최적화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f(x)의 1차 미분과 2차 미분을 사용하여 x를 갱신함\n",
    "$$x \\leftarrow  x-\\frac{{f}'(x)}{{f}''(x)}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ f(x)=x^{4}-2x^{2} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 variable(2.0)\n",
      "1 variable(1.4545454545454546)\n",
      "2 variable(1.1510467893775467)\n",
      "3 variable(1.0253259289766978)\n",
      "4 variable(1.0009084519430513)\n",
      "5 variable(1.0000012353089454)\n",
      "6 variable(1.000000000002289)\n",
      "7 variable(1.0)\n",
      "8 variable(1.0)\n",
      "9 variable(1.0)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from dezero import Variable\n",
    "\n",
    "def f(x):\n",
    "    y = x ** 4 - 2*x**2\n",
    "    return y\n",
    "\n",
    "x = Variable(np.array(2.0))\n",
    "iters = 10\n",
    "\n",
    "for i in range(iters):\n",
    "    print(i, x)\n",
    "    \n",
    "    y = f(x)\n",
    "    x.cleargrad()\n",
    "    y.backward(create_graph=True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    gx = x.grad\n",
    "    x.cleargrad()\n",
    "    gx.backward()\n",
    "    gx2= x.grad\n",
    "    \n",
    "    x.data -= gx.data / gx2.data\n",
    "    \"\"\"Function of Newton method\n",
    "    Executing twice backward method for automic differentiation \n",
    "    \n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}